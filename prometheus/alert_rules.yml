groups:
  - name: flask_app_alerts
    interval: 30s
    rules:
      # CRITICAL: Service is down
      - alert: FlaskAppDown
        expr: up{job="flask-app"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Flask app is down"
          description: "Flask app has been unreachable for 1 minute. Check if service is running."
          
      # CRITICAL: High error rate (>5%)
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(flask_request_count_total{status=~"5.."}[5m]))
            /
            sum(rate(flask_request_count_total[5m]))
          ) > 0.05
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected (>5%)"
          description: "{{ $value | humanizePercentage }} of requests are failing with 5xx errors."
          
      # WARNING: High latency
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, 
            sum by (le) (rate(flask_request_latency_seconds_bucket[5m]))
          ) > 0.5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High P95 latency detected"
          description: "P95 latency is {{ $value }}s (threshold: 0.5s). Users experiencing slow responses."
          
      # WARNING: Elevated error rate (1-5%)
      - alert: ElevatedErrorRate
        expr: |
          (
            sum(rate(flask_request_count_total{status=~"5.."}[5m]))
            /
            sum(rate(flask_request_count_total[5m]))
          ) > 0.01
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Elevated error rate detected (>1%)"
          description: "{{ $value | humanizePercentage }} of requests are failing. Monitor closely."
